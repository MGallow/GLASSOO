% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{lassoc}
\alias{lassoc}
\title{Lasso Regression (c++)}
\usage{
lassoc(XX, XY, initB, ind, lam = 0.1, crit = "loss", tol = 1e-04,
  maxit = 10000)
}
\arguments{
\item{XX}{matrix}

\item{XY}{matrix}

\item{initB}{initialization for beta regression coefficients.}

\item{ind}{optional matrix specifying which coefficients will be penalized.}

\item{lam}{tuning parameter for lasso regularization term. Defaults to 'lam = 0.1'}

\item{crit}{criterion for convergence. Criterion \code{loss} will loop until the change in the objective after an iteration over the parameter set is less than \code{tol}. Criterion \code{sum} will loop until the sum change in the estimate after an interation over the parameter set is less than \code{tol} times tolerance multiple. Similary, criterion \code{max} will loop until the maximum change is less than \code{tol} times tolerance multiple. Defaults to \code{loss}.}

\item{tol}{tolerance for algorithm convergence. Defaults to 1e-4}

\item{maxit}{maximum iterations. Defaults to 1e4}
}
\value{
returns list of returns which includes:
\item{Iterations}{number of iterations.}
\item{Coefficients}{estimated regression coefficients.}
\item{H}{update H matrix.}
}
\description{
Computes the coefficient estimates for lasso-penalized linear regression.
}
\details{
For details on the implementation of 'GLASSOO', see the vignette
\url{https://mgallow.github.io/GLASSOO/}.
}
\references{
\itemize{
\item 
For more information on the coordinate descent algorithm, see: \cr
Friedman, Jerome, et al. "Pathwise coordinate optimization." \emph{The Annals of Applied Statistics} 1.2 (2007): 302-332.\cr
\url{https://arxiv.org/pdf/0708.1485.pdf}
}
}
\author{
Matt Galloway \email{gall0441@umn.edu}
}
\keyword{internal}
